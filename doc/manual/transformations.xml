<chapter xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xml:id="chap-transformation">

	<title>The Disnix model transformation pipeline</title>

	<para>
		As explained in <xref linkend="chap-basicusage" /> and <xref linkend="chap-packages" />
		the Disnix input models (services, infrastructure, distribution and packages models) are <emphasis>declarative</emphasis> --
		the models express properties of a service-oriented system and Disnix <emphasis>infers</emphasis> all activities that it needs to execute to get the system deployed, such as building
		the services, transferring services and their intra-dependencies to target machines in the network and activating the services in the right order.
	</para>

	<para>
		Although it may look conceptually simple, inferring deployment activities is all but a trivial job. Whilst the Disnix input models are declarative, they are not
		<emphasis>executable</emphasis> -- there is not a one-on-one mapping between properties in the input models and the activities that Disnix needs to carry out.
		To allow deployment activities to be executed, the input models need to be transformed into a single executable model. The transformation pipeline generates several intermediate models
		to achieve this goal.
	</para>

	<para>
		<figure xml:id="fig-transformations">
			<title>Disnix inputs models and intermediate models</title>
			<mediaobject>
				<imageobject>
					<imagedata fileref="transformations.png" format="PNG"/>
				</imageobject>
			</mediaobject>
		</figure>
	</para>

	<para>
		<xref linkend="fig-transformations" /> is a diagram that summarizes the transformation proces and the intermediate models:
	</para>

	<itemizedlist>
		<listitem>
			<para>
				The <emphasis>deployment architecture</emphasis> model unifies the four separated models: services, infrastructure, distribution and packages
				models into one single declarative specification. The distribution concern is eliminated by merging the distribution model properties
				into the services model properties.
			</para>
		</listitem>
		<listitem>
			<para>
				The <emphasis>normalized deployment architecture</emphasis> is an augmented version of the deployment architecture model with default properties and evaluated
				package build functions (for each service) added to the Nix profiles to be distributed to the target machines.
			</para>
		</listitem>
		<listitem>
			<para>
				The <emphasis>deployment</emphasis> model is a specification that provides one-on-one mappings of Nix profiles to machines, services to containers, and
				snapshots to containers. From this specification Disnix can automatically infer the activities for the distribution, activation and data migration phases.
			</para>
		</listitem>
		<listitem>
			<para>
				The <emphasis>build</emphasis> model is a specification that provides one-on-one mappings of Nix store derivation files to target machines. From this specification
				Disnix can delegate builds to remote machines and fetch their results back.
			</para>
		</listitem>
	</itemizedlist>

	<para>
		In addition to the common Disnix inputs models, it is also possible to provide specifications of the intermediate models and use them for deploying a service oriented system.
		Having the ability to work with intermediate models is useful for experimentation and integration purposes.
		The next sections explain the purposes of the artifacts, how they are specified and how they can be used.
	</para>

	<section>
		<title>Unifying the input models into a single specification: deployment architecture model</title>

		<para>
			The first step in transforming the input models into a single executable specification, is unifying the specifications
			into one single declarative specification, that is called a <emphasis>deployment architecture</emphasis> model.

			<example xml:id="ex-deployment-architecture-model">
				<title>Deployment architecture model for the <code>StaffTracker</code> example</title>
<programlisting>
{system, pkgs}:

let customPkgs = import ../top-level/all-packages.nix { inherit system; };
in
{
  targetPackages = { <co xml:id='co-architecture-model-packages' />
    test1 = [
      pkgs.wget
    ];
    test2 = [
      pkgs.curl
    ];
  };

  services = rec { <co xml:id='co-architecture-model-services' />

    StaffService = {
      name = "StaffService";
      pkg = customPkgs.StaffService;
      dependsOn = {
        inherit staff;
      };
      type = "tomcat-webapplication";

      targets = [ infrastructure.test1 infrastructure.test2 ]; <co xml:id='co-architecture-model-targets' />
    };

    ...
  };

  infrastructure = { <co xml:id='co-architecture-model-infrastructure' />
    test1 = {
      properties = {
        hostname = "test1.example.org";
      };

      containers = {
        tomcat-webapplication = {
          tomcatPort = 8080;
        };
      };

      system = "i686-linux";
    };

    ...
  };
}
</programlisting>
			</example>
		</para>

		<para>
			<xref linkend="ex-deployment-architecture-model" /> shows a deployment architecture model for a particular
			deployment scenario of the <code>StaffTracker</code> system.
		</para>

		<calloutlist>
			<callout arearefs='co-architecture-model-packages'>
				<para>
					The <varname>targetPackages</varname> attribute refers to the properties that were originally
					defined in a packages model, such as <xref linkend="ex-packages-model-nixpkgs" />.
				</para>
			</callout>

			<callout arearefs='co-architecture-model-services'>
				<para>
					The <varname>services</varname> attribute refers to the services that were originally defined in
					the services model shown in <xref linkend="ex-services-model" /> and captures the exact same properties.
				</para>
			</callout>

			<callout arearefs='co-architecture-model-infrastructure'>
				<para>
					The <varname>infrastructure</varname> attribute refers to the target machines that were orginally defined in the
					infrastructure model shown in <xref linkend="ex-infrastructure-model" /> and captures the exact same properties.
				</para>
			</callout>

			<callout arearefs='co-architecture-model-targets'>
				<para>
					The distribution concern is completely eliminated in the deployment architecture model. The distribution mappings
					defined in <xref linkend="ex-distribution-model" /> have been augmented to the corresponding services. For example,
					the targets of the <varname>StaffService</varname> mapping have been augmented as the <varname>targets</varname> attribute
					to the <varname>StaffService</varname> service.
				</para>
			</callout>
		</calloutlist>

		<para>
			In addition to the standard Disnix input possible models, it is also possible to write a deployment architecture model and deploy it as follows:
<screen>
$ disnix-env -A architecture.nix
</screen>
		</para>
	</section>

	<section>
		<title>Normalizing the deployment architecture model</title>

		<para>
			Unifying models into a single deployment architecture specification is a good
			first step in producing an executable specification, but more needs to be
			done to fully reach that goal. To generate an exectable deployment model, we
			must provide reasonable default settings for unspecified system properties, propagate
			inter-dependency parameters to the services, and build packages for
			all required system architectures.
		</para>

		<para>
			The <varname>infrastructure</varname> section in the deployment architecture model
			gets normalized by augmenting each target with default values --
			every target machine in the infrastructure model has specialized
			settings for connecting to the target machines, building packages and running
			tasks concurrently:
<programlisting>
test2 = {
  properties = {
    hostname = "test2.example.org";
  };

  containers = {
    tomcat-webapplication = {
      tomcatPort = 8080;
    };

    mysql-database = {
      mysqlPort = 3306;
      mysqlUsername = "root";
      mysqlPassword = "admin";
    };

    system = "x86_64-linux";
    numOfCores = 1;
    clientInterface = "disnix-ssh-client";
    targetProperty = "hostname";
  };
};
</programlisting>
		</para>
		<para>
			If none of these advanced settings are provided, Disnix will make the following assumptions:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					If no system architecture was specified (<varname>system</varname>), Disnix assumes that the target machine has
					the same system architecture as the coordinator machine (so that the Nix package manager does not have
					to delegate a build to a machine that has a compatible architecture)
				</para>
			</listitem>
			<listitem>
				<para>
					By default, Disnix uses the Disnix SSH client (<code>disnix-ssh-client</code>)
					interface executable (<varname>clientInterface</varname>)
					to connect to the target machine.
				</para>
			</listitem>
			<listitem>
				<para>
					By default, Disnix uses the <varname>hostname</varname> property as a connection
					string.
				</para>
			</listitem>
			<listitem>
				<para>
					Normally, Disnix runs only one activity per target machine concurrently: <varname>numOfCores</varname>
					unless this property is overridden to another value.
				</para>
			</listitem>
		</itemizedlist>

		<para>
			The <varname>services</varname> in the deployment architecture model are normalized as follows:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					Each service can indicate whether they want their state to be managed by Dysnomia
					(with the property: <varname>deployState</varname>), so that data will automatically be migrated
					when moving the service from one machine to another. The default setting is <code>false</code>
					and can be overridden with the <code>--deploy-state</code> parameter.
				</para>
				<para>
					If a service does not specify this property, then Disnix will automatically propagate the default setting as a parameter.
				</para>
			</listitem>
			<listitem>
				<para>
					The <varname>targets</varname> attribute gets translated to a reference specification, so that we can refer
					to the normalized variants of the services and targets through a service's inter-dependency parameters.
					For example, the following service with an abstract targets specification:
<programlisting>
staff = rec {
  name = "staff";
  targets = [ infrastructure.test1 infrastructure.test2 ];
  type = "mysql-database";
};
</programlisting>
					gets translated into the following reference specification:
<programlisting>
staff = rec {
  name = "staff";
  targets = [
    { target = "test1"; container = "mysql-database"; }
    { target = "test2"; container = "mysql-database"; }
  ];
  type = "mysql-database";
}
</programlisting>
				</para>
				<para>
					As explained in <xref linkend="chap-advanced-options" />, the <varname>targets</varname>
					property -- that maps services to target machines -- does not only map services to machines, but
					also to container services hosted on that machine. In most cases, you will only use one container
					instance per service type -- for example, running two MySQL DBMS services (e.g. one on TCP port
					<code>3306</code> and another on <code>3307</code>) is far less common use case scenario.
				</para>
				<para>
					If no container mapping is provided, Disnix will do an auto-mapping to a container service
					that corresponds to the service's <varname>type</varname> property.
				</para>
			</listitem>
			<listitem>
				<para>
					Similarly, the inter-dependency specifiers (<varname>dependsOn</varname>, <varname>connectsTo</varname>,
					<varname>activatesAfter</varname>) get translated to reference specifications as well.
					Typically, inter-dependency specifications are only specified on a functional level -- a service
					typically only specifies that it depends on another service disregarding the location
					where that service may have been deployed.
				</para>
				<para>
					For example, the following service with the following inter-dependencies:
<programlisting>
StaffService = {
  name = "StaffService";
  dependsOn = {
    inherit staff;
  };
  type = "tomcat-webapplication";
};
</programlisting>
				</para>
				<para>
					gets translated to:
<programlisting>
StaffService = {
  name = "StaffService";
  dependsOn = {
    staff = {
      service = "staff";
      targets = [ { target = "test1"; container = "mysql-database" } ];
    };
  };
  type = "tomcat-webapplication";
};
</programlisting>

				</para>
				<para>
					As shown in the example above, an inter-dependency specification does not only refer to the service, but also
					to targets where the inter-dependency has been deployed to.
				</para>
				<para>
					If no target location was specified, then Disnix will assume that the service has
					an inter-dependency on all possible locations where that dependency may be
					deployed. If an inter-dependency is redundantly deployed, then that service also
					has an inter-dependency on all redundant replicas.
				</para>
				<para>
					The fact that it is also possible to specify the targets of the inter-dependencies,
					makes it also possible to optimize certain deployments. For example, you can also
					optimize a service's performance by forcing it to bind to an inter-dependency that
					is deployed to the same target machine, so that it will not be affected by slow network
					connectivity.
				</para>
			</listitem>
			<listitem>
				<para>
					The last ingredient to generate an executable specification is building the services from source code so that we can map
					their build results to the target machines. To accomplish this, Disnix generates the <varname>pkgs</varname> attribute
					that refers to the build result for each potential system architecture the service is deployed to:
<programlisting>
StaffService = {
  name = "StraffTracker";
  pkg = customPkgs.StaffService;
  dependsOn = {
    inherit staff;
  };
  type = "tomcat-webapplication";

  ...

  pkgs = {
    "x86_64-linux" = "/nix/store/91abq...-StaffService";
    "x86_64-darwin" = "/nix/store/f1ap2...-StaffService";
  };
};
</programlisting>

				</para>
			</listitem>
		</itemizedlist>

		<para>
			Finally, it will compose a deployment architecture model attribute named: <varname>targetPackages</varname>
			(or augment the existing <varname>targetPackages</varname> attribute set if one exists already) that refers to a list of
			Nix store paths to be distributed to each machine in the network:
<programlisting>
{
  targetPackages = {
    test1 = [
      "/nix/store/91abq...-HelloDBService"
    ];

    test2 = [
      "/nix/store/p9af1...-HelloMySQLDB"
    ];
  };

  services = ...
  infrastructure = ...
}
</programlisting>
		</para>
	</section>

	<section>
		<title>Generating a deployment model</title>

		<para>
			With a normalized architecture model, we can generate an executable specification that is called the
			<emphasis>deployment model</emphasis>. The deployment model can be used for executing all remaining
			activities after the services have been built.
		</para>

		<para>
			<example xml:id="ex-deployment-model">
				<title>A deployment model for the <code>StaffTracker</code> example</title>
<programlisting>
{
  profiles = { <co xml:id='co-deploy-model-profiles' />
    test1 = "/nix/store/...-test1";
    test2 = "/nix/store/...-test2";
  };

  services = { <co xml:id='co-deploy-model-services' />
    "ekfekrerw..." = {
      name = "staff";
      pkg = "/nix/store/...";
      type = "mysql-database";
      dependsOn = [
      ];
      connectsTo = [
      ];
    };

    "dfsjs9349..." = {
      name = "StaffService";
      pkg = "/nix/store/...";
      type = "tomcat-webapplication";
      dependsOn = [
        { target = "test1";
          container = "mysql-database";
          service = "ekfekrerw...";
        }
      ];
      connectsTo = [
      ];
    };
  };

  infrastructure = { <co xml:id='co-deploy-model-infrastructure' />
    test1 = {
      properties = {
        hostname = "test1.example.org";
      };
      containers = {
        apache-webapplication = {
          documentRoot = "/var/www";
        };
      };
      system = "x86_64-linux";
      numOfCores = 1;
      clientInterface = "disnix-ssh-client";
      targetProperty = "hostname";
    };
    test2 = {
      properties = {
        hostname = "test2.example.org";
      };
      containers = {
        mysql-database = {
          mysqlPort = "3306";
        };
      };
      system = "x86_64-linux";
      numOfCores = 1;
      clientInterface = "disnix-ssh-client";
      targetProperty = "hostname";
    };
  };

  serviceMappings = [ <co xml:id='co-deploy-model-service-mappings' />
    { service = "ekfekrerw...";
      target = "test2";
      container = "mysql-database";
    }
    { service = "dfsjs9349...";
      target = "test1";
      container = "tomcat-webapplication";
    }
  ];

  snapshotMappings = [ <co xml:id='co-deploy-model-snapshot-mappings' />
    { service = "ekfekrerw...";
      component = "rooms";
      container = "mysql-database";
      target = "test2";
    }
  ];
}
</programlisting>
			</example>

			<xref linkend="ex-deployment-model" /> shows an example of a deployment model where the normalized deployment architecture model can be translated to:
		</para>

		<calloutlist>
			<callout arearefs='co-deploy-model-profiles'>
				<para>
					The <varname>profiles</varname> attribute refers to Nix profiles
					mapped to target machines and is derived from the <varname>targetPackages</varname>
					property in the normalized deployment architecture model. From the <varname>profiles</varname>
					property Disnix derives all steps of the <emphasis>distribution phase</emphasis> in which
					all packages and their intra-dependencies are copied to machines in the network.
				</para>
			</callout>
			<callout arearefs='co-deploy-model-services'>
				<para>
					The <varname>services</varname> attribute refers to all services that can be mapped to machines.
					The keys in this attribute set are SHA256 hash codes are recursively computed from the
					Nix store path of the package, the type, and all the inter-dependency mappings.
					Using hash codes to identify the services makes it possible to easily see whether a service is
					identical to another or not (by comparing hash codes), so that upgrades can be done more efficiently.
				</para>
			</callout>
			<callout arearefs='co-deploy-model-infrastructure'>
				<para>
					The <varname>infrastructure</varname> attribute is unchanged compared to the deployment
					architecture model and still stores target machine properties.
				</para>
			</callout>
			<callout arearefs='co-deploy-model-service-mappings'>
				<para>
					The <varname>serviceMappings</varname> attribute maps services in the <varname>services</varname>
					attribute set, to target machines in the network stored in the <varname>infrastructure</varname>
					attribute set and containers hosted on the target machines.
				</para>
				<para>
					From these mappings, Disnix can derive the steps to activate and deactivate the
					services of which a system is composed, ensure that all dependencies are present
					and that the services are activated or deactivated in the right order.
				</para>
			</callout>
			<callout arearefs='co-deploy-model-snapshot-mappings'>
				<para>
					The <varname>snapshotMappings</varname> attribute state that for each services mapped to a
					target machines and container, we also want to <emphasis>migrate</emphasis> the state
					(by taking and restoring snapshots) if the service gets moved from one machine to another.
				</para>
			</callout>
		</calloutlist>

		<para>
			Although a deployment model is quite low-level, it is also possible to manually write one, and deploy it by running:
<screen>
$ disnix-env -D deployment.nix
</screen>
			<command>disnix-env</command> invokes an external executable called: <command>disnix-deploy</command> that executes
			the remaining activities of deployment process after the build process succeeds.
			<command>disnix-depoy</command> as well as the tools that execute individual deployment activities are driven by <emphasis>manifest</emphasis>
			files. A manifest file is simply a one-on-one translation of the deployment model in the Nix expression language
			to XML following the NixXML convention.
		</para>
	</section>

	<section>
		<title>Generating a build model</title>

		<para>
			As explained in <xref linkend="chap-basicusage" />, Disnix can also optionally delegate builds to the target machines in the network.
			When build delegation is enabled, Disnix generates a <emphasis>build model</emphasis> from a normalized deployment architecture model:

			<example xml:id="ex-build-model">
				<title>A build model for the <code>StaffTracker</code> example</title>
<programlisting>
{
  derivations = [ <co xml:id='co-build-model-derivations' />
    { "/nix/store/staff-....drv"; interface = "test1"; }
    { "/nix/store/StaffService-....drv"; interface = "test2"; }
  ];

  interfaces = { <co xml:id='co-build-model-interfaces' />
    test1 = {
      targetAddress = "test1.example.org";
      clientInterface = "disnix-ssh-client";
    };

    test2 = {
      targetAddress = "test2.example.org";
      clientInterface = "disnix-ssh-client";
    };
  };
}
</programlisting>
			</example>
			<xref linkend="ex-build-model" /> shows an example of a build model where the normalized deployment architecture model can be translated to:
		</para>

		<calloutlist>
			<callout arearefs='co-build-model-derivations'>
				<para>
					The <varname>derivations</varname> attribute maps Nix store derivation files to machines in the network that should perform the build.
					This information is used by Disnix to delegate store derivation closure to target machines, use Nix to build the packages
					remotely, and fetch the build results back to the coordinator machine.
				</para>
			</callout>
			<callout arearefs='co-build-model-interfaces'>
				<para>
					The <varname>interfaces</varname> attribute is a sub set of the <varname>infrastructure</varname> model that contains
					the connectivity settings for each target machine.
				</para>
			</callout>
		</calloutlist>

		<para>
			By running the following command, you can execute a build model to delegate builds to
			remote machines and fetch their results back:
<screen>
$ disnix-delegate -B build.nix
</screen>
			If the build delegation option is enabled (for example, by passing <code>--build-on-targets</code>
			parameter to <command>disnix-env</command>) then Disnix will work a so-called <emphasis>distributed derivation file</emphasis>.
			Similar to a manifest file, a distributed derivation file is a one-on-one translation from the build model
			written in the Nix expression language to XML using the NixXML convention.
		</para>
	</section>
</chapter>
